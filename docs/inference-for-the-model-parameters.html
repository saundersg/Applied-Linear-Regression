<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9 Inference for the Model Parameters | Introduction</title>
  <meta name="description" content="9 Inference for the Model Parameters | Introduction" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="9 Inference for the Model Parameters | Introduction" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9 Inference for the Model Parameters | Introduction" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="transformations.html"/>
<link rel="next" href="lowess-and-loess-curves.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#regression-cheat-sheet"><i class="fa fa-check"></i><b>1.1</b> Regression Cheat Sheet</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-mathematical-model.html"><a href="the-mathematical-model.html"><i class="fa fa-check"></i><b>2</b> The Mathematical Model</a><ul>
<li class="chapter" data-level="2.1" data-path="the-mathematical-model.html"><a href="the-mathematical-model.html#part-1-the-true-line"><i class="fa fa-check"></i><b>2.1</b> Part 1: The True Line</a></li>
<li class="chapter" data-level="2.2" data-path="the-mathematical-model.html"><a href="the-mathematical-model.html#part-2-the-dots"><i class="fa fa-check"></i><b>2.2</b> Part 2: The <em>Dots</em></a></li>
<li class="chapter" data-level="2.3" data-path="the-mathematical-model.html"><a href="the-mathematical-model.html#part-3-the-estimated-line"><i class="fa fa-check"></i><b>2.3</b> Part 3: The <em>Estimated Line</em></a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="interpreting-the-model-parameters.html"><a href="interpreting-the-model-parameters.html"><i class="fa fa-check"></i><b>3</b> Interpreting the Model Parameters</a></li>
<li class="chapter" data-level="4" data-path="residuals-and-errors.html"><a href="residuals-and-errors.html"><i class="fa fa-check"></i><b>4</b> Residuals and Errors</a></li>
<li class="chapter" data-level="5" data-path="assessing-the-fit-of-a-regression.html"><a href="assessing-the-fit-of-a-regression.html"><i class="fa fa-check"></i><b>5</b> Assessing the Fit of a Regression</a></li>
<li class="chapter" data-level="6" data-path="residual-plots-and-regression-assumptions.html"><a href="residual-plots-and-regression-assumptions.html"><i class="fa fa-check"></i><b>6</b> Residual Plots and Regression Assumptions</a><ul>
<li class="chapter" data-level="6.1" data-path="residual-plots-and-regression-assumptions.html"><a href="residual-plots-and-regression-assumptions.html#residuals-versus-fitted-values-plot-checks-assumptions-1-and-3"><i class="fa fa-check"></i><b>6.1</b> Residuals versus Fitted-values Plot: Checks Assumptions #1 and #3</a></li>
<li class="chapter" data-level="6.2" data-path="residual-plots-and-regression-assumptions.html"><a href="residual-plots-and-regression-assumptions.html#q-q-plot-of-the-residuals-checks-assumption-2"><i class="fa fa-check"></i><b>6.2</b> Q-Q Plot of the Residuals: Checks Assumption #2</a></li>
<li class="chapter" data-level="6.3" data-path="residual-plots-and-regression-assumptions.html"><a href="residual-plots-and-regression-assumptions.html#residuals-versus-order-plot-checks-assumption-5"><i class="fa fa-check"></i><b>6.3</b> Residuals versus Order Plot: Checks Assumption #5</a></li>
<li class="chapter" data-level="6.4" data-path="residual-plots-and-regression-assumptions.html"><a href="residual-plots-and-regression-assumptions.html#problems-from-failed-assumptions"><i class="fa fa-check"></i><b>6.4</b> Problems from Failed Assumptions</a><ul>
<li class="chapter" data-level="6.4.1" data-path="residual-plots-and-regression-assumptions.html"><a href="residual-plots-and-regression-assumptions.html#lack-of-linearity"><i class="fa fa-check"></i><b>6.4.1</b> Lack of Linearity</a></li>
<li class="chapter" data-level="6.4.2" data-path="residual-plots-and-regression-assumptions.html"><a href="residual-plots-and-regression-assumptions.html#non-normal-error-terms"><i class="fa fa-check"></i><b>6.4.2</b> Non-normal Error Terms</a></li>
<li class="chapter" data-level="6.4.3" data-path="residual-plots-and-regression-assumptions.html"><a href="residual-plots-and-regression-assumptions.html#constant-variance-assumption-violated"><i class="fa fa-check"></i><b>6.4.3</b> Constant Variance Assumption Violated</a></li>
<li class="chapter" data-level="6.4.4" data-path="residual-plots-and-regression-assumptions.html"><a href="residual-plots-and-regression-assumptions.html#independence-assumption-violated"><i class="fa fa-check"></i><b>6.4.4</b> Independence Assumption Violated</a></li>
<li class="chapter" data-level="6.4.5" data-path="residual-plots-and-regression-assumptions.html"><a href="residual-plots-and-regression-assumptions.html#outliers-present"><i class="fa fa-check"></i><b>6.4.5</b> Outliers Present</a></li>
<li class="chapter" data-level="6.4.6" data-path="residual-plots-and-regression-assumptions.html"><a href="residual-plots-and-regression-assumptions.html#all-assumptions-satisfied"><i class="fa fa-check"></i><b>6.4.6</b> All Assumptions Satisfied</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="estimating-the-model-parameters.html"><a href="estimating-the-model-parameters.html"><i class="fa fa-check"></i><b>7</b> Estimating the Model Parameters</a><ul>
<li class="chapter" data-level="7.1" data-path="estimating-the-model-parameters.html"><a href="estimating-the-model-parameters.html#least-squares"><i class="fa fa-check"></i><b>7.1</b> Least Squares</a></li>
<li class="chapter" data-level="7.2" data-path="estimating-the-model-parameters.html"><a href="estimating-the-model-parameters.html#maximum-likelihood"><i class="fa fa-check"></i><b>7.2</b> Maximum Likelihood</a></li>
<li class="chapter" data-level="7.3" data-path="estimating-the-model-parameters.html"><a href="estimating-the-model-parameters.html#estimating-the-model-variance"><i class="fa fa-check"></i><b>7.3</b> Estimating the Model Variance</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="transformations.html"><a href="transformations.html"><i class="fa fa-check"></i><b>8</b> Transformations</a><ul>
<li class="chapter" data-level="8.1" data-path="transformations.html"><a href="transformations.html#y-transformations"><i class="fa fa-check"></i><b>8.1</b> Y-Transformations</a><ul>
<li class="chapter" data-level="8.1.1" data-path="transformations.html"><a href="transformations.html#scatterplot-recognition"><i class="fa fa-check"></i><b>8.1.1</b> Scatterplot Recognition</a></li>
<li class="chapter" data-level="8.1.2" data-path="transformations.html"><a href="transformations.html#box-cox-suggestion"><i class="fa fa-check"></i><b>8.1.2</b> Box-Cox Suggestion</a></li>
<li class="chapter" data-level="8.1.3" data-path="transformations.html"><a href="transformations.html#an-example"><i class="fa fa-check"></i><b>8.1.3</b> An Example</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="transformations.html"><a href="transformations.html#x-transformations"><i class="fa fa-check"></i><b>8.2</b> X-Transformations</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="inference-for-the-model-parameters.html"><a href="inference-for-the-model-parameters.html"><i class="fa fa-check"></i><b>9</b> Inference for the Model Parameters</a><ul>
<li class="chapter" data-level="9.1" data-path="inference-for-the-model-parameters.html"><a href="inference-for-the-model-parameters.html#tTests"><i class="fa fa-check"></i><b>9.1</b> t Tests</a></li>
<li class="chapter" data-level="9.2" data-path="inference-for-the-model-parameters.html"><a href="inference-for-the-model-parameters.html#confidence-intervals"><i class="fa fa-check"></i><b>9.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="9.3" data-path="inference-for-the-model-parameters.html"><a href="inference-for-the-model-parameters.html#Ftests"><i class="fa fa-check"></i><b>9.3</b> F tests</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="lowess-and-loess-curves.html"><a href="lowess-and-loess-curves.html"><i class="fa fa-check"></i><b>10</b> Lowess (and Loess) Curves</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inference-for-the-model-parameters" class="section level1">
<h1><span class="header-section-number">9</span> Inference for the Model Parameters</h1>
<p><span class="expand-caption">t test formulas, sampling distributions, confidence intervals, and F tests…</span></p>
<p>We are sometimes interested in making inference about <span class="math inline">\(\beta_0\)</span>, the y-intercept. However, most inference in regression is focused on the slope, <span class="math inline">\(\beta_1\)</span>. Recall that the interpretation of <span class="math inline">\(\beta_1\)</span> is the amount of increase (or decrease) in the expected value (average value) of <span class="math inline">\(Y\)</span> per unit change in <span class="math inline">\(X\)</span>.</p>
<p>Two types of inference about <span class="math inline">\(\beta_1\)</span>, or similarly <span class="math inline">\(\beta_0\)</span> when applicable, are of interest.</p>
<table class="fancytable">
<tr>
<th>
<strong>Hypotheses</strong>
</th>
<th>
<strong>Test Statistic</strong>
</th>
<th>
<strong>P-value</strong>
</th>
</tr>
<tr>
<td style="text-align:center;width:25%;">
<p><span class="math inline">\(H_0: \beta_0 =\)</span> <span class="tooltiprbold">
<span class="math inline">\(\underbrace{0}_\text{a number}\)</span>
<span class="tooltiprtext">This could be any number, not just 0. However, the default summar(mylm) output in R only shows the test statistic and p-value for the test that uses 0. To test a different value, you would need to compute the test statistic and p-value by hand using the formula shown.</span>
</span></p>
<p><span class="math inline">\(H_a: \beta_0\)</span><span class="tooltiprbold">
<span class="math inline">\(\,\neq\,\)</span>
<span class="tooltiprtext">You could use <span class="math inline">\(&gt;\)</span> or <span class="math inline">\(&lt;\)</span> instead of <span class="math inline">\(\neq\)</span> for the alternative hypothesis. By default, the p-value from summary(mylm) in R uses <span class="math inline">\(\neq\)</span>.</span>
</span><span class="tooltiprbold">
<span class="math inline">\(\underbrace{0}_\text{a number}\)</span>
<span class="tooltiprtext">This could be any number, not just 0. However, the default summar(mylm) output in R only shows the test statistic and p-value for the test that uses 0. To test a different value, you would need to compute the test statistic and p-value by hand using the formula shown.</span>
</span></p>
</td>
<td style="text-align:center;width:25%;">
<p><span class="tooltiprbold">
<span class="math display">\[t = \frac{b_0 - \overbrace{0}^\text{a number}}{s_{b_0}}\]</span>
<span class="tooltiprtext">This is the formula for the test statistic. It measures how far the estimated y-intercept <span class="math inline">\(b_0\)</span> is from the null hypothesis for <span class="math inline">\(\beta_0\)</span> in units of “standard errors of <span class="math inline">\(b_0\)</span>”. Thus the division by <span class="math inline">\(s_{b_0}\)</span>. Though the hypothesized value of <span class="math inline">\(\beta_0\)</span> is typically 0, it could be any number.</span>
</span></p>
</td>
<td style="text-align:center;width:50%;">
<img src="_main_files/figure-html/unnamed-chunk-31-1.png" width="672" />
</td>
</tr>
<tr>
<td style="text-align:center;width:25%;">
<p><span class="math inline">\(H_0: \beta_1 =\)</span> <span class="tooltiprbold">
<span class="math inline">\(\underbrace{0}_\text{a number}\)</span>
<span class="tooltiprtext">This could be any number, not just 0. However, the default summar(mylm) output in R only shows the test statistic and p-value for the test that uses 0. To test a different value, you would need to compute the test statistic and p-value by hand using the formula shown.</span>
</span></p>
<p><span class="math inline">\(H_a: \beta_1\)</span><span class="tooltiprbold">
<span class="math inline">\(\,\neq\,\)</span>
<span class="tooltiprtext">You could use <span class="math inline">\(&gt;\)</span> or <span class="math inline">\(&lt;\)</span> instead of <span class="math inline">\(\neq\)</span> for the alternative hypothesis. By default, the p-value from summary(mylm) in R uses <span class="math inline">\(\neq\)</span>.</span>
</span><span class="tooltiprbold">
<span class="math inline">\(\underbrace{0}_\text{a number}\)</span>
<span class="tooltiprtext">This could be any number, not just 0. However, the default summar(mylm) output in R only shows the test statistic and p-value for the test that uses 0. To test a different value, you would need to compute the test statistic and p-value by hand using the formula shown.</span>
</span></p>
</td>
<td style="text-align:center;width:25%;">
<p><span class="tooltiprbold">
<span class="math display">\[t = \frac{b_1 - \overbrace{0}^\text{a number}}{s_{b_1}}\]</span>
<span class="tooltiprtext">This is the formula for the test statistic. It measures how far the estimated slope <span class="math inline">\(b_1\)</span> is from the null hypothesis for <span class="math inline">\(\beta_1\)</span> in units of “standard errors of <span class="math inline">\(b_1\)</span>”. Thus the division by <span class="math inline">\(s_{b_1}\)</span>. Though the hypothesized value of <span class="math inline">\(\beta_1\)</span> is typically 0, it could be any number.</span>
</span></p>
</td>
<td>
<p>Left-tailed p-value = <code>pt(-abs(tvalue), degrees of freedom)</code>.</p>
Double it to get the two-sided p-value.
</td>
</tr>
</table>
<table class="fancytable">
<tr>
<th>
<strong>Confidence Interval</strong>
</th>
<th>
<strong>Formula</strong>
</th>
<th>
<strong>Standard Error</strong>
</th>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\beta_0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(b_0 \pm\)</span><span class="tooltiprbold">
<span class="math inline">\(t^*\)</span>
<span class="tooltiprtext">This is called the “critical value” and denotes the number of standard deviations that are needed to obtain a 95% confidence interval from a t distribution with degrees of freedom <span class="math inline">\(n-p\)</span> (sample size - number of parameters in the regression model).</span>
</span><span class="tooltiprbold">
<span class="math inline">\(\cdot\)</span>
<span class="tooltiprtext">The critical value is multiplied by the standard error of <span class="math inline">\(b_0\)</span>.</span>
</span><span class="tooltiprbold">
<span class="math inline">\(s_{b_0}\)</span>
<span class="tooltiprtext">The standard error of <span class="math inline">\(b_0\)</span>, denoted by <span class="math inline">\(s_{b_0}\)</span> is provided in the regression summary output under the column header called “Std. Error” for the “(Intercept)” row of the output. It is calculated using the formula shown below.</span>
</span>
</td>
<td style="text-align:center;">
<span class="tooltiprbold">
<span class="math display">\[s^2_{b_0} = MSE\left[\frac{1}{n} + \frac{\bar{X}^2}{\sum(X_i-\bar{X})^2}\right]\]</span>
<span class="tooltiprtext">This is called the “estimated variance of <span class="math inline">\(b_0\)</span>”. Taking the square root of this number gives the “standard error of <span class="math inline">\(b_0\)</span>”.</span>
</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\beta_1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(b_1 \pm\)</span><span class="tooltiprbold">
<span class="math inline">\(t^*\)</span>
<span class="tooltiprtext">This is called the “critical value” and denotes the number of standard deviations that are needed to obtain a 95% confidence interval from a t distribution with degrees of freedom <span class="math inline">\(n-p\)</span> (sample size - number of parameters in the regression model).</span>
</span><span class="tooltiprbold">
<span class="math inline">\(\cdot\)</span>
<span class="tooltiprtext">The critical value is multiplied by the standard error of <span class="math inline">\(b_1\)</span>.</span>
</span><span class="tooltiprbold">
<span class="math inline">\(s_{b_1}\)</span>
<span class="tooltiprtext">The standard error of <span class="math inline">\(b_1\)</span>, denoted by <span class="math inline">\(s_{b_1}\)</span> is provided in the regression summary output under the column header called “Std. Error”. It is calculated using the formula shown below.</span>
</span>
</td>
<td style="text-align:center;">
<span class="tooltiprbold">
<span class="math display">\[s^2_{b_1} = \frac{MSE}{\sum(X_i-\bar{X})^2}\]</span>
<span class="tooltiprtext">This is called the “estimated variance of <span class="math inline">\(b_1\)</span>”. Taking the square root of this number gives the “standard error of <span class="math inline">\(b_1\)</span>”.</span>
</span>
</td>
</tr>
</table>
<p>To be more exact, the types of inference we are interested in are the following.</p>
<ol style="list-style-type: decimal">
<li><p>Determine if there is evidence of a meaningful linear relationship in the data. If <span class="math inline">\(\beta_1 = 0\)</span>, then there is no relation between <span class="math inline">\(X\)</span> and <span class="math inline">\(E\{Y\}\)</span>. Hence we might be interested in testing the hypotheses
<span class="math display">\[
  H_0: \beta_1 = 0
\]</span>
<span class="math display">\[
  H_a: \beta_1 \neq 0 
\]</span></p></li>
<li><p>Determine if the slope is greater, less than, or different from some other hypothesized value. In this case, we would be interested in using hypotheses of the form
<span class="math display">\[
  H_0: \beta_1 = \beta_{10}
\]</span>
<span class="math display">\[
  H_a: \beta_1 \neq \beta_{10} 
\]</span>
where <span class="math inline">\(\beta_{10}\)</span> is some hypothesized number.</p></li>
<li><p>To provide a confidence interval for the true value of <span class="math inline">\(\beta_1\)</span>.</p></li>
</ol>
<p><br /></p>
<p>Before we discuss how to test the hypotheses listed above or construct a confidence interval, we must understand the <strong>sampling distribution</strong> of the estimate <span class="math inline">\(b_1\)</span> of the parameter <span class="math inline">\(\beta_1\)</span>. And, while we are at it, we may as well come to understand the sampling distribution of the estimate <span class="math inline">\(b_0\)</span> of the parameter <span class="math inline">\(\beta_0\)</span>.</p>
<div style="padding-left:30px;color:darkgray;font-size:.8em;">
<p>Review <a href="http://statistics.byuimath.com/index.php?title=Lesson_6:_Distribution_of_Sample_Means_%26_The_Central_Limit_Theorem#Introduction_to_Sampling_Distributions">sampling distributions</a> from Math 221.</p>
</div>
<p>Since <span class="math inline">\(b_1\)</span> is an estimate, it will vary from sample to sample, even though the truth, <span class="math inline">\(\beta_1\)</span>, remains fixed. (The same holds for <span class="math inline">\(b_0\)</span> and <span class="math inline">\(\beta_0\)</span>.) It turns out that the sampling distribution of <span class="math inline">\(b_1\)</span> (where the <span class="math inline">\(X\)</span> values remain fixed from study to study) is normal with mean and variance:
<span class="math display">\[
  \mu_{b_1} = \beta_1
\]</span>
<span class="math display">\[
  \sigma^2_{b_1} = \frac{\sigma^2}{\sum(X_i-\bar{X})^2}
\]</span></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="inference-for-the-model-parameters.html#cb10-1"></a><span class="co">## Simulation to Show relationship between Standard Errors</span></span>
<span id="cb10-2"><a href="inference-for-the-model-parameters.html#cb10-2"></a></span>
<span id="cb10-3"><a href="inference-for-the-model-parameters.html#cb10-3"></a><span class="co">##-----------------------------------------------</span></span>
<span id="cb10-4"><a href="inference-for-the-model-parameters.html#cb10-4"></a><span class="co">## Edit anything in this area... </span></span>
<span id="cb10-5"><a href="inference-for-the-model-parameters.html#cb10-5"></a></span>
<span id="cb10-6"><a href="inference-for-the-model-parameters.html#cb10-6"></a>n &lt;-<span class="st"> </span><span class="dv">100</span> <span class="co">#sample size</span></span>
<span id="cb10-7"><a href="inference-for-the-model-parameters.html#cb10-7"></a>Xstart &lt;-<span class="st"> </span><span class="dv">30</span> <span class="co">#lower-bound for x-axis</span></span>
<span id="cb10-8"><a href="inference-for-the-model-parameters.html#cb10-8"></a>Xstop &lt;-<span class="st"> </span><span class="dv">100</span> <span class="co">#upper-bound for x-axis</span></span>
<span id="cb10-9"><a href="inference-for-the-model-parameters.html#cb10-9"></a></span>
<span id="cb10-10"><a href="inference-for-the-model-parameters.html#cb10-10"></a>beta_<span class="dv">0</span> &lt;-<span class="st"> </span><span class="dv">2</span> <span class="co">#choice of true y-intercept</span></span>
<span id="cb10-11"><a href="inference-for-the-model-parameters.html#cb10-11"></a>beta_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="fl">3.5</span> <span class="co">#choice of true slope</span></span>
<span id="cb10-12"><a href="inference-for-the-model-parameters.html#cb10-12"></a>sigma &lt;-<span class="st"> </span><span class="fl">13.8</span> <span class="co">#choice of st. deviation of error terms</span></span>
<span id="cb10-13"><a href="inference-for-the-model-parameters.html#cb10-13"></a></span>
<span id="cb10-14"><a href="inference-for-the-model-parameters.html#cb10-14"></a><span class="co">## End of Editable area.</span></span>
<span id="cb10-15"><a href="inference-for-the-model-parameters.html#cb10-15"></a><span class="co">##-----------------------------------------------</span></span>
<span id="cb10-16"><a href="inference-for-the-model-parameters.html#cb10-16"></a></span>
<span id="cb10-17"><a href="inference-for-the-model-parameters.html#cb10-17"></a></span>
<span id="cb10-18"><a href="inference-for-the-model-parameters.html#cb10-18"></a><span class="co"># Create X, which will be used in the next R-chunk.</span></span>
<span id="cb10-19"><a href="inference-for-the-model-parameters.html#cb10-19"></a>X &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">seq</span>(Xstart,Xstop, <span class="dt">length.out=</span>n<span class="op">/</span><span class="dv">2</span>), <span class="dt">each=</span><span class="dv">2</span>) </span>
<span id="cb10-20"><a href="inference-for-the-model-parameters.html#cb10-20"></a></span>
<span id="cb10-21"><a href="inference-for-the-model-parameters.html#cb10-21"></a><span class="co">## After playing this chunk, play the next chunk as well.</span></span></code></pre></div>
<p>To see that this is true, consider the regression model with values specified for each parameter as follows.</p>
<p><span class="math display">\[
  Y_i = \overbrace{\beta_0}^{2} + \overbrace{\beta_1}^{3.5} X_i + \epsilon_i \quad \text{where} \ \epsilon_i \sim N(0, \overbrace{\sigma^2}^{\sigma=13.8})
\]</span></p>
<p>Using the equations above for <span class="math inline">\(\mu_{b_1}\)</span> and <span class="math inline">\(\sigma^2_{b_1}\)</span> we obtain that the mean of the sampling distribution of <span class="math inline">\(b_1\)</span> will be</p>
<p><span class="math inline">\(\mu_{b_1} = \beta_1 = 3.5\)</span></p>
<p>Further, we see that the variance of the sampling distribution of <span class="math inline">\(b_1\)</span> will be</p>
<p><span class="math inline">\(\sigma^2_{b_1} = \frac{\sigma^2}{\sum(X_i-\bar{X})^2} = \frac{13.8^2}{4.25\times 10^{4}}\)</span></p>
<p>Taking the square root of the variance, the standard deviation of the sampling distribution of <span class="math inline">\(b_1\)</span> will be</p>
<p><span class="math inline">\(\sigma_{b_1} = 0.067\)</span>.</p>
<p>That’s very nice. But to really believe it, let’s run a simulation ourselves. The “Code” below is worth studying. It runs a simulation that (1) takes a sample of data from the true regression relation, (2) fits the sampled data with an estimated regression equation (gray lines in the plot), and (3) computes the estimated values of <span class="math inline">\(b_1\)</span> and <span class="math inline">\(b_0\)</span> for that regression.</p>
<p>After doing this many, many times, the results of every single regression are plotted (in gray lines, which creates a gray shaded region because there are so many lines) in the scatterplot below. Further, each obtained estimate of <span class="math inline">\(b_0\)</span> is plotted in the histogram on the left (below the scatterplot) and each obtained estimate of <span class="math inline">\(b_1\)</span> is plotted in the histogram on the right. Looking at the histograms carefully, it can be seen that the mean of each histogram is very close to the true parameter value of <span class="math inline">\(\beta_0\)</span> or <span class="math inline">\(\beta_1\)</span>, respectively. Also, the “Std. Error” of each histogram is incredibly close (if not exact to 3 decimal places) to the computed value of <span class="math inline">\(\sigma_{b_0}\)</span> and <span class="math inline">\(\sigma_{b_1}\)</span>, respectively. Amazing!</p>
<p><img src="_main_files/figure-html/unnamed-chunk-33-1.png" width="768" /></p>
<div id="tTests" class="section level2">
<h2><span class="header-section-number">9.1</span> t Tests</h2>
<p>Using the information above about the sampling distributions of <span class="math inline">\(b_1\)</span> and <span class="math inline">\(b_0\)</span>, an immediate choice of statistical test to test the hypotheses
<span class="math display">\[
  H_0: \beta_1 = \beta_{10} 
\]</span>
<span class="math display">\[
  H_a: \beta_1 \neq \beta_{10} 
\]</span>
where <span class="math inline">\(\beta_{10}\)</span> can be zero, or any other value, is a t test given by
<span class="math display">\[
  t = \frac{b_1 - \beta_{10}}{s_{b_1}}
\]</span>
where <span class="math inline">\(s^2_{b_1} = \frac{MSE}{\sum(X_i-\bar{X})^2}\)</span>. (You may want to review the section “Estimating the Model Variance” of this file to know where MSE came from.) With quite a bit of work it has been shown that <span class="math inline">\(t\)</span> is distributed as a <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n-2\)</span> degrees of freedom. The nearly identical test statistic for testing
<span class="math display">\[
  H_0: \beta_0 = \beta_{00}
\]</span>
<span class="math display">\[
  H_a: \beta_0 \neq \beta_{00} 
\]</span>
is given by
<span class="math display">\[
  t = \frac{b_0 - \beta_{00}}{s_{b_0}}
\]</span>
where <span class="math inline">\(s^2_{b_0} = MSE\left[\frac{1}{n}+\frac{\bar{X}^2}{\sum(X_i-\bar{X})^2}\right]\)</span>. This version of <span class="math inline">\(t\)</span> has also been shown to be distributed as a <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n-2\)</span> degrees of freedom.</p>
</div>
<div id="confidence-intervals" class="section level2">
<h2><span class="header-section-number">9.2</span> Confidence Intervals</h2>
<p>Creating a confidence interval for either <span class="math inline">\(\beta_1\)</span> or <span class="math inline">\(\beta_0\)</span> follows immediately from these results using the formulas
<span class="math display">\[
  b_1 \pm t^*_{n-2}\cdot s_{b_1}
\]</span>
<span class="math display">\[
  b_0 \pm t^*_{n-2}\cdot s_{b_0}
\]</span>
where <span class="math inline">\(t^*_{n-2}\)</span> is the critical value from a t distribution with <span class="math inline">\(n-2\)</span> degrees of freedom corresponding to the chosen confidence level.</p>
<p><br /></p>
</div>
<div id="Ftests" class="section level2">
<h2><span class="header-section-number">9.3</span> F tests</h2>
<p>Another way to test the hypotheses
<span class="math display">\[
  H_0: \beta_1 = \beta_{10}  \quad\quad \text{or} \quad\quad H_0: \beta_0 = \beta_{00}
\]</span>
<span class="math display">\[
  H_a: \beta_1 \neq \beta_{10} \quad\quad \ \ \quad \quad H_a: \beta_0 \neq \beta_{00}
\]</span>
is with an <span class="math inline">\(F\)</span> Test. One downside of the F test is that we cannot construct confidence intervals. Another is that we can only perform two-sided tests, we cannot use one-sided alternatives with an F test. The upside is that an <span class="math inline">\(F\)</span> test is very general and can be used in many places that a t test cannot.</p>
<p>In its most general form, the <span class="math inline">\(F\)</span> test partitions the sums of squared errors into different pieces and compares the pieces to see what is accounting for the most variation in the data. To test the hypothesis that <span class="math inline">\(H_0:\beta_1=0\)</span> against the alternative that <span class="math inline">\(H_a: \beta_1\neq 0\)</span>, we are essentially comparing two models against each other. If <span class="math inline">\(\beta_1=0\)</span>, then the corresponding model would be <span class="math inline">\(E\{Y_i\} = \beta_0\)</span>. If <span class="math inline">\(\beta_1\neq0\)</span>, then the model remains <span class="math inline">\(E\{Y_i\}=\beta_0+\beta_1X_i\)</span>. We call the model corresponding to the null hypothesis the reduced model because it will always have fewer parameters than the model corresponding to the alternative hypothesis (which we call the full model). This is the first requirement of the <span class="math inline">\(F\)</span> Test, that the null model (reduced model) have fewer “free” parameters than the alternative model (full model). To demonstrate what we mean by “free” parameters, consider the following example.</p>
<p>Say we wanted to test the hypothesis that <span class="math inline">\(H_0:\beta_1 = 2.5\)</span> against the alternative that <span class="math inline">\(\beta_1\neq2.5\)</span>. Then the null, or reduced model, would be <span class="math inline">\(E\{Y_i\}=\beta_0+2.5X_i\)</span>. The alternative, or full model, would be <span class="math inline">\(E\{Y_i\}=\beta_0+\beta_1X_i\)</span>. Thus, the null (reduced) model contains only one “free” parameter because <span class="math inline">\(\beta_1\)</span> has been fixed to be 2.5 and is no longer free to be estimated from the data. The alternative (full) model contains two “free” parameters, both are to be estimated from the data. The null (reduced) model must contain fewer free parameters than the alternative (full) model.</p>
<p>Once the null and alternative models have been specified, the General Linear Test is performed by appropriately partitioning the squared errors into pieces corresponding to each model. In the first example where we were testing <span class="math inline">\(H_0: \beta_1=0\)</span> against <span class="math inline">\(H_a:\beta_1\neq0\)</span> we have the partition
<span class="math display">\[
  \underbrace{Y_i-\bar{Y}}_{Total} = \underbrace{\hat{Y}_i - \bar{Y}}_{Regression} + \underbrace{Y_i-\hat{Y}_i}_{Error}
\]</span>
The reason we use <span class="math inline">\(\bar{Y}\)</span> for the null model is that <span class="math inline">\(\bar{Y}\)</span> is the unbiased estimator of <span class="math inline">\(\beta_0\)</span> for the null model, <span class="math inline">\(E\{Y_i\} = \beta_0\)</span>. Thus we would compute the following sums of squares:
<span class="math display">\[
  SSTO = \sum(Y_i-\bar{Y})^2
\]</span>
<span class="math display">\[
  SSR = \sum(\hat{Y}_i-\bar{Y})^2
\]</span>
<span class="math display">\[
  SSE = \sum(Y_i-\hat{Y}_i)^2
\]</span>
and note that <span class="math inline">\(SSTO = SSR + SSE\)</span>. Important to note is that <span class="math inline">\(SSTO\)</span> uses the difference between the observations <span class="math inline">\(Y_i\)</span> and the null (reduced) model. The <span class="math inline">\(SSR\)</span> uses the diffences between the alternative (full) and null (reduced) model. The <span class="math inline">\(SSE\)</span> uses the differences between the observations <span class="math inline">\(Y_i\)</span> and the alternative (full) model. From these we could set up a General <span class="math inline">\(F\)</span> table of the form</p>
<table style="width:100%;">
<colgroup>
<col width="21%" />
<col width="21%" />
<col width="10%" />
<col width="23%" />
<col width="23%" />
</colgroup>
<thead>
<tr class="header">
<th> </th>
<th>Sum Sq</th>
<th>Df</th>
<th>Mean Sq</th>
<th>F Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Model Error</td>
<td><span class="math inline">\(SSR\)</span></td>
<td><span class="math inline">\(df_R-df_F\)</span></td>
<td><span class="math inline">\(\frac{SSR}{df_R-df_F}\)</span></td>
<td><span class="math inline">\(\frac{SSR}{df_R-df_F}\cdot\frac{df_F}{SSE}\)</span></td>
</tr>
<tr class="even">
<td>Residual Error</td>
<td><span class="math inline">\(SSE\)</span></td>
<td><span class="math inline">\(df_F\)</span></td>
<td><span class="math inline">\(\frac{SSE}{df_F}\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td>Total Error</td>
<td><span class="math inline">\(SSTO\)</span></td>
<td><span class="math inline">\(df_R\)</span></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="transformations.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="lowess-and-loess-curves.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
